{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Algorithm\n",
    "\n",
    "A machine learning tutorial from https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/\n",
    "\n",
    "Reimplemented in Scala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Naive Bayes\n",
    "The Naive Bayes algorithm is an intuitive method that uses the probabilities of each attribute belonging to each class to make a prediction. It is the supervised learning approach you would come up with if you wanted to model a predictive modeling problem probabilistically.\n",
    "\n",
    "Naive bayes simplifies the calculation of probabilities by assuming that the probability of each attribute belonging to a given class value is independent of all other attributes. This is a strong assumption but results in a fast and effective method.\n",
    "\n",
    "The probability of a class value given a value of an attribute is called the conditional probability. By multiplying the conditional probabilities together for each attribute for a given class value, we have a probability of a data instance belonging to that class.\n",
    "\n",
    "To make a prediction we can calculate probabilities of the instance belonging to each class and select the class value with the highest probability.\n",
    "\n",
    "Naive bases is often described using categorical data because it is easy to describe and calculate using ratios. A more useful version of the algorithm for our purposes supports numeric attributes and assumes the values of each numerical attribute are normally distributed (fall somewhere on a bell curve). Again, this is a strong assumption, but still gives robust results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the Onset of Diabetes\n",
    "The test problem we will use in this tutorial is the Pima Indians Diabetes problem.\n",
    "\n",
    "This problem is comprised of 768 observations of medical details for Pima indians patents. The records describe instantaneous measurements taken from the patient such as their age, the number of times pregnant and blood workup. All patients are women aged 21 or older. All attributes are numeric, and their units vary from attribute to attribute.\n",
    "\n",
    "Each record has a class value that indicates whether the patient suffered an onset of diabetes within 5 years of when the measurements were taken (1) or not (0).\n",
    "\n",
    "This is a standard dataset that has been studied a lot in machine learning literature. A good prediction accuracy is 70%-76%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Algorithm Tutorial\n",
    "\n",
    "This tutorial is broken down into the following steps:\n",
    "\n",
    "1. **Handle Data**: Load the data from CSV file and split it into training and test datasets.\n",
    "2. **Summarize Data**: summarize the properties in the training dataset so that we can calculate probabilities and make predictions.\n",
    "3. **Make a Prediction**: Use the summaries of the dataset to generate a single prediction.\n",
    "4. **Make Predictions**: Generate predictions given a test dataset and a summarized training dataset.\n",
    "5. **Evaluate Accuracy**: Evaluate the accuracy of predictions made for a test dataset as the percentage correct out of all predictions made.\n",
    "6. **Tie it Together**: Use all of the code elements to present a complete and standalone implementation of the Naive Bayes algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mscala.collection.mutable.ArrayBuffer\n",
       "\n",
       "\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mloadCsv\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.collection.mutable.ArrayBuffer\n",
    "\n",
    "def loadCsv(filename: String): List[List[Double]] = {\n",
    "    val bufferedSource = io.Source.fromFile(filename)\n",
    "    val rows = ArrayBuffer[List[Double]]()\n",
    "    for (line <- bufferedSource.getLines) {\n",
    "        rows += line.split(\",\").map(_.trim).map(_.toDouble).toList\n",
    "    }\n",
    "    bufferedSource.close\n",
    "    rows.toList\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mutil.Random\n",
       "\n",
       "\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36msplitDataset\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import util.Random\n",
    "\n",
    "def splitDataset(dataset: List[List[Double]], splitRatio: Double): (List[List[Double]], List[List[Double]]) = {\n",
    "    val shuffled = Random.shuffle(dataset)\n",
    "    shuffled.splitAt((dataset.length * splitRatio).toInt)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mseparateByClass\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def separateByClass(dataset: List[List[Double]]): Map[Double, List[List[Double]]] = dataset.groupBy(_.last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mcalcMeanStd\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mmean\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mstdev\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// TODO: validate this implementation, is the python one better?\n",
    "def calcMeanStd(x: List[Double]): (Double, Double) = {\n",
    "    @scala.annotation.tailrec\n",
    "    def meanStd(x: List[Double], mu: Double, Q: Double, count: Int): (Double, Double) = {\n",
    "        if (count >= x.length) (mu, Math.sqrt(Q / x.length))\n",
    "        else {\n",
    "            val newCount = count + 1\n",
    "            val newMu = x(count) / newCount + mu * (1.0 - 1.0 / newCount)\n",
    "            val newQ = Q + (x(count) - mu) * (x(count) - newMu)\n",
    "            meanStd(x, newMu, newQ, newCount)   \n",
    "        }        \n",
    "    }\n",
    "\n",
    "    meanStd(x, 0.0, 0.0, 0)    \n",
    "}\n",
    "\n",
    "def mean(numbers: List[Double]): Double = calcMeanStd(numbers)._1\n",
    "def stdev(numbers: List[Double]): Double = calcMeanStd(numbers)._2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36msummarize\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize(dataset: List[List[Double]]): List[(Double, Double)] = dataset.transpose.dropRight(1).map(calcMeanStd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36msummarizeByClass\u001b[39m"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarizeByClass(dataset: List[List[Double]]): Map[Double, List[(Double, Double)]] = separateByClass(dataset).map {\n",
    "    case (a, b) => (a, summarize(b))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mscala.math.{exp, pow, sqrt, Pi}\n",
       "\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mcalculateProbability\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.math.{exp, pow, sqrt, Pi}\n",
    "def calculateProbability(x: Double, mean: Double, stdev: Double): Double = {\n",
    "    val exponent = exp(-(pow(x - mean, 2) / (2 * pow(stdev, 2))))\n",
    "    (1 / (math.sqrt(2 * Pi) * stdev)) * exponent\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mcalculateClassProbabilities\u001b[39m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculateClassProbabilities(summaries: Map[Double, List[(Double, Double)]], inputVector: List[Double]) = {\n",
    "    summaries.map{ case (classValue, classSummaries) => (classValue, classSummaries.foldLeft(1.0) {\n",
    "        (acc, tup) => calculateProbability(inputVector.head, tup._1, tup._2)\n",
    "    } ) }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mpredict\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(summaries: Map[Double, List[(Double, Double)]], inputVector: List[Double]) = {\n",
    "    calculateClassProbabilities(summaries, inputVector).maxBy(_._2)._1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mgetPredictions\u001b[39m"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getPredictions(summaries: Map[Double, List[(Double, Double)]], inputVector: List[List[Double]]) = {\n",
    "    for (iv <- inputVector) yield predict(summaries, iv)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mgetAccuracy\u001b[39m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getAccuracy(testSet: List[List[Double]], predictions: List[Double]): Double = {\n",
    "    val correct = for ( (data: List[Double], prediction: Double) <- testSet zip predictions) yield data.last == prediction\n",
    "    (correct.filter(_ == true).length / testSet.length.toDouble) * 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtestSet\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mList\u001b[39m[\u001b[32mDouble\u001b[39m]] = \u001b[33mList\u001b[39m(\n",
       "  \u001b[33mList\u001b[39m(\u001b[32m1.0\u001b[39m, \u001b[32m1.0\u001b[39m, \u001b[32m1.0\u001b[39m, \u001b[32m0.0\u001b[39m),\n",
       "  \u001b[33mList\u001b[39m(\u001b[32m2.0\u001b[39m, \u001b[32m2.0\u001b[39m, \u001b[32m2.0\u001b[39m, \u001b[32m0.0\u001b[39m),\n",
       "  \u001b[33mList\u001b[39m(\u001b[32m3.0\u001b[39m, \u001b[32m3.0\u001b[39m, \u001b[32m3.0\u001b[39m, \u001b[32m1.0\u001b[39m)\n",
       ")\n",
       "\u001b[36mpredictions\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mDouble\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m0.0\u001b[39m, \u001b[32m0.0\u001b[39m, \u001b[32m0.0\u001b[39m)\n",
       "\u001b[36mres12_2\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m66.66666666666666\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val testSet = List(List(1.0, 1.0, 1.0, 0.0), List(2.0, 2.0, 2.0, 0.0), List(3.0, 3.0, 3.0, 1.0))\n",
    "val predictions = List(0.0, 0.0, 0.0)\n",
    "getAccuracy(testSet, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mmain\u001b[39m"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def main() = {\n",
    "    val filename = \"pima-indians-diabetes.data.csv\"\n",
    "    val splitRatio = 0.67\n",
    "    val dataset = loadCsv(filename)\n",
    "    val (trainingSet, testSet) = splitDataset(dataset, splitRatio)\n",
    "    print(s\"Split ${dataset.length} rows into train=${trainingSet.length} and test=${testSet.length} rows\\n\")\n",
    "    val summaries = summarizeByClass(trainingSet)\n",
    "    val predictions = getPredictions(summaries, testSet)\n",
    "    val accuracy = getAccuracy(testSet, predictions)\n",
    "    print(s\"Accuracy: $accuracy\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 768 rows into train=514 and test=254 rows\n",
      "Accuracy: 68.11023622047244"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "2.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
